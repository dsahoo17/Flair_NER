{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMt/t0JxwEffzpT7O9gS5yT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsahoo17/GestureRecognition/blob/master/Flair_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyOjVrf4NHUh",
        "colab_type": "code",
        "outputId": "787d25ab-3a95-4959-86ee-215c5d4e4154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# !pip install --upgrade git+https://github.com/flairNLP/flair.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/flairNLP/flair.git\n",
            "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-kvw8qjz6\n",
            "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-kvw8qjz6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: pytest>=5.3.2 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (5.4.2)\n",
            "Requirement already satisfied, skipping upgrade: transformers>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.5.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.2.10)\n",
            "Requirement already satisfied, skipping upgrade: langdetect in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.5.10)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (0.1.9)\n",
            "Requirement already satisfied, skipping upgrade: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (0.13.1)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (8.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair==0.4.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.5) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.4.5) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair==0.4.5) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.6.0->flair==0.4.5) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (1.13.13)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.5) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (1.16.13)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.15.2)\n",
            "Building wheels for collected packages: flair\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.4.5-cp36-none-any.whl size=148758 sha256=a4515072aea35d84c56c59f1a5e398d13ac67bbf8d2c4757639d495806024d35\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3y0amwp_/wheels/84/82/73/d2b3b59b7be74ea05f2c6d64132efe27df52daffb47d1dc7bb\n",
            "Successfully built flair\n",
            "Installing collected packages: flair\n",
            "  Found existing installation: flair 0.4.5\n",
            "    Uninstalling flair-0.4.5:\n",
            "      Successfully uninstalled flair-0.4.5\n",
            "Successfully installed flair-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iantTaGM3xHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9ftlbgfM-U6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import CSVClassificationCorpus, ColumnCorpus\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings,DocumentLSTMEmbeddings, BertEmbeddings, StackedEmbeddings, TokenEmbeddings\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.models import SequenceTagger\n",
        "from typing import List\n",
        "from flair.data import Sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP5paEQ5N3By",
        "colab_type": "code",
        "outputId": "4ef38a16-4833-4f68-bfa9-cb2969d9dc4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with open('/home/test.txt', 'r') as test_txt: \n",
        "    print(test_txt.read())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "show O\n",
            "me O\n",
            "the O\n",
            "flights O\n",
            "to O\n",
            "love I-location_detail\n",
            "field I-location_detail\n",
            "\n",
            "show O\n",
            "me O\n",
            "all O\n",
            "flights O\n",
            "from O\n",
            "boston I-location_detail\n",
            "to O\n",
            "denver I-location_detail\n",
            "\n",
            "philadelphia I-location_detail\n",
            "to O\n",
            "san I-location_detail\n",
            "francisco I-location_detail\n",
            "monday I-depart\n",
            "\n",
            "from O\n",
            "san O\n",
            "francisco O\n",
            "on O\n",
            "tuesday I-depart\n",
            "\n",
            "show O\n",
            "me O\n",
            "all O\n",
            "flights O\n",
            "from O\n",
            "san I-location_detail\n",
            "francisco I-location_detail\n",
            "to O\n",
            "washington I-location_detail\n",
            "dc I-location_detail\n",
            "area O\n",
            "\n",
            "sure O\n",
            "i O\n",
            "want O\n",
            "to O\n",
            "go O\n",
            "from O\n",
            "philadelphia I-location_detail\n",
            "to O\n",
            "dallas I-location_detail\n",
            "\n",
            "show O\n",
            "me O\n",
            "all O\n",
            "the O\n",
            "available O\n",
            "flights O\n",
            "from O\n",
            "baltimore I-location_detail\n",
            "to O\n",
            "dallas I-location_detail\n",
            "with O\n",
            "economy I-aircraft_detail\n",
            "fares O\n",
            "\n",
            "show O\n",
            "me O\n",
            "the O\n",
            "flights O\n",
            "from O\n",
            "philadelphia I-location_detail\n",
            "to O\n",
            "atlanta I-location_detail\n",
            "\n",
            "show O\n",
            "me O\n",
            "the O\n",
            "latest I-flight_detail\n",
            "dinner I-aircraft_detail\n",
            "flight O\n",
            "from O\n",
            "baltimore I-location_detail\n",
            "to O\n",
            "oakland I-location_detail\n",
            "\n",
            "philadelphia I-location_detail\n",
            "to O\n",
            "dallas I-location_detail\n",
            "arriving O\n",
            "before I-arrive\n",
            "1 I-arrive\n",
            "in O\n",
            "the O\n",
            "afternoon I-arrive\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i519oJePQ37",
        "colab_type": "code",
        "outputId": "b43d9482-3c31-474f-e55c-7e928390911a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with open('/home/test.txt', 'r') as train_txt: \n",
        "    print(train_txt.read())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "show O\n",
            "me O\n",
            "the O\n",
            "flights O\n",
            "to O\n",
            "love I-location_detail\n",
            "field I-location_detail\n",
            "\n",
            "show O\n",
            "me O\n",
            "all O\n",
            "flights O\n",
            "from O\n",
            "boston I-location_detail\n",
            "to O\n",
            "denver I-location_detail\n",
            "\n",
            "philadelphia I-location_detail\n",
            "to O\n",
            "san I-location_detail\n",
            "francisco I-location_detail\n",
            "monday I-depart\n",
            "\n",
            "from O\n",
            "san O\n",
            "francisco O\n",
            "on O\n",
            "tuesday I-depart\n",
            "\n",
            "show O\n",
            "me O\n",
            "all O\n",
            "flights O\n",
            "from O\n",
            "san I-location_detail\n",
            "francisco I-location_detail\n",
            "to O\n",
            "washington I-location_detail\n",
            "dc I-location_detail\n",
            "area O\n",
            "\n",
            "sure O\n",
            "i O\n",
            "want O\n",
            "to O\n",
            "go O\n",
            "from O\n",
            "philadelphia I-location_detail\n",
            "to O\n",
            "dallas I-location_detail\n",
            "\n",
            "show O\n",
            "me O\n",
            "all O\n",
            "the O\n",
            "available O\n",
            "flights O\n",
            "from O\n",
            "baltimore I-location_detail\n",
            "to O\n",
            "dallas I-location_detail\n",
            "with O\n",
            "economy I-aircraft_detail\n",
            "fares O\n",
            "\n",
            "show O\n",
            "me O\n",
            "the O\n",
            "flights O\n",
            "from O\n",
            "philadelphia I-location_detail\n",
            "to O\n",
            "atlanta I-location_detail\n",
            "\n",
            "show O\n",
            "me O\n",
            "the O\n",
            "latest I-flight_detail\n",
            "dinner I-aircraft_detail\n",
            "flight O\n",
            "from O\n",
            "baltimore I-location_detail\n",
            "to O\n",
            "oakland I-location_detail\n",
            "\n",
            "philadelphia I-location_detail\n",
            "to O\n",
            "dallas I-location_detail\n",
            "arriving O\n",
            "before I-arrive\n",
            "1 I-arrive\n",
            "in O\n",
            "the O\n",
            "afternoon I-arrive\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gqTIylgW4l5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj73Ih39V7UQ",
        "colab_type": "code",
        "outputId": "5b8f5727-c1dc-4a94-b0de-441872f9968e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_folder = \"./\"+os.sep+'33'\n",
        "model_dir = \"./\"\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                                      train_file='/home/test.txt',\n",
        "                                      test_file='/home/test.txt',\n",
        "                                      # dev_file='dev.txt'\n",
        "                                      )\n",
        "\n",
        "tag_type = 'ner'\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "\n",
        "            WordEmbeddings('glove'),\n",
        "\n",
        "            # comment in this line to use character embeddings\n",
        "            # CharacterEmbeddings(),\n",
        "\n",
        "            # comment in these lines to use flair embeddings\n",
        "            FlairEmbeddings('news-forward'),\n",
        "            FlairEmbeddings('news-backward'),\n",
        "        ]\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                                embeddings=embeddings,\n",
        "                                                tag_dictionary=tag_dictionary,\n",
        "                                                tag_type=tag_type,\n",
        "                                                use_crf=True)\n",
        "        # 6. initialize the text classifier trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "        # 7. start the training\n",
        "\n",
        "trainer.train(model_dir,learning_rate=0.1,mini_batch_size=32, max_epochs=10,embeddings_storage_mode='cpu',)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-23 16:40:26,063 Reading data from 33\n",
            "2020-05-23 16:40:26,064 Train: /home/test.txt\n",
            "2020-05-23 16:40:26,065 Dev: None\n",
            "2020-05-23 16:40:26,066 Test: /home/test.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-23 16:40:28,036 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:28,037 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('glove')\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
            "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-05-23 16:40:28,040 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:28,041 Corpus: \"Corpus: 9 train + 1 dev + 10 test sentences\"\n",
            "2020-05-23 16:40:28,042 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:28,043 Parameters:\n",
            "2020-05-23 16:40:28,044  - learning_rate: \"0.1\"\n",
            "2020-05-23 16:40:28,045  - mini_batch_size: \"32\"\n",
            "2020-05-23 16:40:28,046  - patience: \"3\"\n",
            "2020-05-23 16:40:28,047  - anneal_factor: \"0.5\"\n",
            "2020-05-23 16:40:28,048  - max_epochs: \"10\"\n",
            "2020-05-23 16:40:28,049  - shuffle: \"True\"\n",
            "2020-05-23 16:40:28,049  - train_with_dev: \"False\"\n",
            "2020-05-23 16:40:28,050  - batch_growth_annealing: \"False\"\n",
            "2020-05-23 16:40:28,051 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:28,052 Model training base path: \".\"\n",
            "2020-05-23 16:40:28,053 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:28,054 Device: cpu\n",
            "2020-05-23 16:40:28,055 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:28,056 Embeddings storage mode: cpu\n",
            "2020-05-23 16:40:28,058 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-23 16:40:30,821 epoch 1 - iter 1/1 - loss 18.47010231 - samples/sec: 11.59\n",
            "2020-05-23 16:40:30,854 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:30,855 EPOCH 1 done: loss 18.4701 - lr 0.1000000\n",
            "2020-05-23 16:40:31,322 DEV : loss 11.07663631439209 - score 0.0\n",
            "2020-05-23 16:40:31,324 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-23 16:40:35,254 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:35,671 epoch 2 - iter 1/1 - loss 12.98898411 - samples/sec: 79.25\n",
            "2020-05-23 16:40:35,683 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:35,684 EPOCH 2 done: loss 12.9890 - lr 0.1000000\n",
            "2020-05-23 16:40:35,714 DEV : loss 12.564239501953125 - score 0.0\n",
            "2020-05-23 16:40:35,716 BAD EPOCHS (no improvement): 1\n",
            "2020-05-23 16:40:35,719 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:36,103 epoch 3 - iter 1/1 - loss 9.67248154 - samples/sec: 83.57\n",
            "2020-05-23 16:40:36,118 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:36,119 EPOCH 3 done: loss 9.6725 - lr 0.1000000\n",
            "2020-05-23 16:40:36,150 DEV : loss 12.634369850158691 - score 0.0\n",
            "2020-05-23 16:40:36,152 BAD EPOCHS (no improvement): 2\n",
            "2020-05-23 16:40:36,153 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:36,533 epoch 4 - iter 1/1 - loss 7.76673031 - samples/sec: 84.58\n",
            "2020-05-23 16:40:36,545 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:36,546 EPOCH 4 done: loss 7.7667 - lr 0.1000000\n",
            "2020-05-23 16:40:36,575 DEV : loss 10.395133972167969 - score 0.0\n",
            "2020-05-23 16:40:36,577 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-23 16:40:40,232 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:40,656 epoch 5 - iter 1/1 - loss 6.78536701 - samples/sec: 75.90\n",
            "2020-05-23 16:40:40,672 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:40,673 EPOCH 5 done: loss 6.7854 - lr 0.1000000\n",
            "2020-05-23 16:40:40,705 DEV : loss 9.02462387084961 - score 0.0\n",
            "2020-05-23 16:40:40,706 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-23 16:40:45,327 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:45,721 epoch 6 - iter 1/1 - loss 5.86019135 - samples/sec: 82.49\n",
            "2020-05-23 16:40:45,733 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:45,734 EPOCH 6 done: loss 5.8602 - lr 0.1000000\n",
            "2020-05-23 16:40:45,765 DEV : loss 11.875739097595215 - score 0.0\n",
            "2020-05-23 16:40:45,766 BAD EPOCHS (no improvement): 1\n",
            "2020-05-23 16:40:45,770 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:46,147 epoch 7 - iter 1/1 - loss 6.28471804 - samples/sec: 85.18\n",
            "2020-05-23 16:40:46,160 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:46,161 EPOCH 7 done: loss 6.2847 - lr 0.1000000\n",
            "2020-05-23 16:40:46,191 DEV : loss 7.381437301635742 - score 0.5\n",
            "2020-05-23 16:40:46,192 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-23 16:40:50,185 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:50,616 epoch 8 - iter 1/1 - loss 5.78783655 - samples/sec: 75.62\n",
            "2020-05-23 16:40:50,628 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:50,629 EPOCH 8 done: loss 5.7878 - lr 0.1000000\n",
            "2020-05-23 16:40:50,657 DEV : loss 10.866893768310547 - score 0.0\n",
            "2020-05-23 16:40:50,658 BAD EPOCHS (no improvement): 1\n",
            "2020-05-23 16:40:50,661 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:51,048 epoch 9 - iter 1/1 - loss 4.93858385 - samples/sec: 83.26\n",
            "2020-05-23 16:40:51,063 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:51,064 EPOCH 9 done: loss 4.9386 - lr 0.1000000\n",
            "2020-05-23 16:40:51,093 DEV : loss 6.731084823608398 - score 0.5\n",
            "2020-05-23 16:40:51,094 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-05-23 16:40:55,805 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:56,217 epoch 10 - iter 1/1 - loss 5.30968428 - samples/sec: 78.62\n",
            "2020-05-23 16:40:56,232 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:40:56,233 EPOCH 10 done: loss 5.3097 - lr 0.1000000\n",
            "2020-05-23 16:40:56,262 DEV : loss 9.967508316040039 - score 0.0\n",
            "2020-05-23 16:40:56,264 BAD EPOCHS (no improvement): 1\n",
            "2020-05-23 16:41:00,213 ----------------------------------------------------------------------------------------------------\n",
            "2020-05-23 16:41:00,214 Testing using best model ...\n",
            "2020-05-23 16:41:00,216 loading file best-model.pt\n",
            "2020-05-23 16:41:04,401 0.7143\t0.6818\t0.6977\n",
            "2020-05-23 16:41:04,402 \n",
            "MICRO_AVG: acc 0.6977 - f1-score 0.6977\n",
            "MACRO_AVG: acc 0.1579 - f1-score 0.1579\n",
            "aircraft_detail tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
            "arrive     tp: 0 - fp: 0 - fn: 2 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
            "depart     tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
            "flight_detail tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
            "location_detail tp: 15 - fp: 6 - fn: 2 - tn: 15 - precision: 0.7143 - recall: 0.8824 - accuracy: 0.7895 - f1-score: 0.7895\n",
            "2020-05-23 16:41:04,403 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [11.07663631439209,\n",
              "  12.564239501953125,\n",
              "  12.634369850158691,\n",
              "  10.395133972167969,\n",
              "  9.02462387084961,\n",
              "  11.875739097595215,\n",
              "  7.381437301635742,\n",
              "  10.866893768310547,\n",
              "  6.731084823608398,\n",
              "  9.967508316040039],\n",
              " 'dev_score_history': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0],\n",
              " 'test_score': 0.6976744186046512,\n",
              " 'train_loss_history': [18.470102310180664,\n",
              "  12.988984107971191,\n",
              "  9.672481536865234,\n",
              "  7.766730308532715,\n",
              "  6.785367012023926,\n",
              "  5.860191345214844,\n",
              "  6.284718036651611,\n",
              "  5.78783655166626,\n",
              "  4.938583850860596,\n",
              "  5.3096842765808105]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A6DGl1zW3IQ",
        "colab_type": "code",
        "outputId": "bb8ba455-7d0d-47bf-d348-0aa940b60355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = SequenceTagger.load('./best-model.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-23 18:39:38,243 loading file ./best-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU4BFWSk1Xvb",
        "colab_type": "code",
        "outputId": "c27558dd-cba5-46f0-a35d-2224ed5c03de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "utt = \" Boston to Chicago\"\n",
        "sentence = Sentence(utt)\n",
        "model.predict(sentence)\n",
        "tagged_entity = sentence.to_tagged_string()\n",
        "print('Single predict: ', tagged_entity)\n",
        "predicted_list = []\n",
        "predicted_list.append(tagged_entity)\n",
        "actual_list = []\n",
        "actual_list.append(utt)\n",
        "slot_dict = {}\n",
        "slots_list = []\n",
        "edited_predicted_list = []\n",
        "output_list = []\n",
        "out_slot = []\n",
        "for s in predicted_list:\n",
        "    edited_predicted_list.append(s.replace(\" <\", \"<\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Single predict:  Boston <I-location_detail> to Chicago <I-location_detail>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSWa6AUE0-o-",
        "colab_type": "code",
        "outputId": "6a4a6ee3-b891-4c57-e777-35db1013348c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(edited_predicted_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Boston<I-location_detail> to Chicago<I-location_detail>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVJwtcXWb3KB",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwWrihzkTziz",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3aYdYROT2Ie",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}